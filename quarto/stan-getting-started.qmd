---
title: "Getting Started with Stan"
subtitle: "in Python with cmdstanpy and plotnine"
author: "Bob Carpenter"
date: "March 27, 2023"
execute:
  cache: false
format:
  html:
    highlight-style: arrow
    mainfont: "Palatino"
    monofont: "Menlo, Lucida Console"
    fontsize: 14pt
    linestretch: 1.5
    number-sections: true
    number-depth: 2
    toc: true
    toc-location: right
    code-fold: true
    css: style.css
  pdf:
    number-sections: true
    number-depth: 2
    shift-heading-level-by: -1
    margin-bottom: 1in
    fig-pos: "t!"
    biblio-title: "References"
    biblio-style: natbib
    link-citations: true
    link-bibliography: true
    pdf-engine: xelatex
bibliography: references.bib
---

# Introduction

These notes are intended to introduce several technical topics to
practitioners: Bayesian statistics and probabilistic modeling, Markov
chain Monte Carlo methods for Bayesian inference, and the Stan
probabilistic programming language.


## Bayesian statistics

The general problem addressed by statistical inference is that of
reasoning from a limited number of noisy observations. For example, we
might want to perform inference about a population after measuring a
subset of its members, or we might want to predict future events after
observing past events.

There are many ways to go about applied statistics.  These notes focus
on Bayesian statistics, a form of statistical modeling and inference
that is grounded in probability theory.  In the Bayesian
apporach to statistics, we characterize our knowledge of the world in
terms of probabilities (e.g., there is a 24.3% chance of rain after
lunch today, the probability that the next baby born in the United
states is male is 51\%).

Bayesian inference is always carried out with respect to a
mathematical model of a stochastic data generating process. If the
model is well-specified in the sense of matching the true data
generating process, then Bayesian statistical inference can be shown
to have several desirable properties, such as calibration and
resistance to overfitting.

## Pre-requisites

I will assume the reader is familiar with the basic notions of
differential and integral calculus in multiple dimensions (e.g., the
typical first- and second-year undergraduate sequence).  But don't
worry, we only need calculus to define what we are computing---the
actual calculations will all be done by Stan.  I will further assume
that the reader is familiar with the basics of matrix operations
(e.g., as taught in an intro to linear algebra class).  

I will further assume that the reader is familiar with basic notions
of probability theory, including discrete and continuous densities,
probability density and mass functions, cumulative distribution
functions, and the basic rules of probability theory (e.g., as taught
in an introduction to mathematical statistics).

I will also assume the reader is familiar with basic Python numerical
programming, including NumPy and SciPy (there are a lot of tutorials
available online and in book form).  I'll be using [Python
3](https://www.python.org/downloads/) with the
[CmdStanPy](https://mc-stan.org/cmdstanpy/installation.html) interface
to Stan.  Click the links and follow the install instructions if you
would like to follow along in code.

## Which Stan interface should I use?

Stan can be accessed directly from the command line or through
analysis languages like Python, R, or Julia.  The compiled model class
can also be accessed directly in these languages.

### CmdStan

The reference implementation of Stan is CmdStan, which is
a command-line interface (CLI) written entirely in C++.  

* [CmdStan](https://mc-stan.org/users/interfaces/cmdstan): CLI

CmdStan produces comma-separated value (CSV) output, which makes it
easy to read into languages such as R, Python, or Julia for further
analysis.

### Out of process interfaces

I would strongly recommend one of the following interfaces, which
write data to a file, execute a separate process for CmdStan, then
read the results in through the file system.

* [CmdStanPy](https://mc-stan.org/cmdstanpy/): Python
* [CmdStanR](https://https://mc-stan.org/cmdstanr/): R
* [Stan.jl](https://mc-stan.org/users/interfaces/julia-stan): Julia

The out-of-process architecture makes these interfaces relatively easy
to install because there are no C++ compatibility issues to work out
between the analysis languages and Stan.  This case study uses
CmdStanPy.

### In process interfaces

The following interfaces were the first two developed for Stan.

* [RStan](http://mc-stan.org/rstan/): R
* [PyStan](https://pystan.readthedocs.io/en/latest/index.html): Python

The Python in-memory interface replaced with the following web service.

* [HttpStan](https://github.com/stan-dev/httpstan): HTTP

Both RStan and HttpStan (and hence PyStan) rely on high-level foreign
function interfaces (FFI) to Stan (specifically Cython and Rcpp),
which means they invoke Stan in memory in the same process running R
or HttpStan.  This induces compatibility requirements between the C++
used for Python and R and the C++ used for compiling a Stan program.
This in turn complicates installation, particularly on Windows.

### Model interface

We have recently developed a more portable in-memory interface to
Stan's log density function along with gradients and Hessians, and the
constraining and unconstraining parameter transforms.  These are coded
using a relatively portable low-level memory interface (`.C` in R,
`.ctypes` in Python).

* [BridgeStan](https://github.com/roualdes/bridgestan): R, Python, Julia, C, Rust 



## Python boilerplate

We include the following Python boilerplate to import and configure
packages we will use throughout these notes.

```{python}
# PROJECT SETUP
import cmdstanpy as csp
import numpy as np
import pandas as pd
import plotnine as pn
import itertools
import logging
import warnings

csp.utils.get_logger().setLevel(logging.WARNING)

warnings.filterwarnings( "ignore", module = "plotnine\..*" )

def mydraw(x):
    x.draw()
```

# Stan for forward simulation

We're first going to consider simple binomial sampling in order to
introduce Stan programs and how they're called and to develop some
intuitions about estimation based on binary outcomes.

Let's say we have 100 trials, each with a 30% chance of success. The
30% might represent a chance of rain and the result the number of days
out of 100 that it actually rained; it might represent the chance of a
drug improving a patient's condition with the result being the number
of patients who improve; or, it might represent the chance of a
successful penalty kick from a given position on a field, and the the
total number representing the number of goals in 100 attempts.

In statistical sampling notation, we write
$$
Y \sim \textrm{binomial}(N, \theta)
$$
to indicate that the random variable $Y$ has a binomial distribution
with $N \in \mathbb{N}$ trials, each with a $\theta \in [0, 1]$ chance
of success. The value of the variable $Y$ will be the number of
successes in $N$ trials with a probability $\theta$ of success. The
probability mass function function for $Y$, written $p_Y$, is defined
by
\begin{align}
p_Y(y \mid N, \theta)
&= \textrm{binomial}(y \mid N, \theta)
\\[6pt]
&=
\binom{N}{y} \cdot \theta^y \cdot (1 - \theta)^{N - y}.
\end{align}
Unless necessary for disambiguation, we will drop the random variable
subscripts on probability density or mass functions like $p_Y$ going forward, writing
simply $p(y \mid N, \theta)$ and allowing context to disambiguate.

## A first Stan program

Now let's say we wanted to generate random instantiations of $Y$ for
given values of $N$ and $\theta$. We can do that using the following
Stan program, which we will unpack line by line after its listing.

```{.stan filename="stan/binomial-rng.stan"}
data {
  int<lower=0> N;
  real<lower=0, upper=1> theta;
}
generated quantities {
  int<lower=0, upper=N> y = binomial_rng(N, theta);
}
```

The first thing to notice is that a Stan program is organized into
blocks.  Here we have two blocks, a _data block_ containing declarations
of variables that must be input as data, and a _generated quantities
block_, which not only declares variables, but assigns to them.

The second thing to notice about a Stan program is that the variables
are all declared with types. Stan uses _static typing_, which means
that unlike Python or R, a variable's type is declared in the program
before it is used rather than determined at run time based on what is
assigned to it. Once declared, a variable's type never changes. Stan
also uses _strong typing_, meaning that unlike C or C++, there is no
way to get around the type restrictions and access memory directly.

The program declares three variables, `N` and `y` of type `int`
(integer values in $\mathbb{Z}$), and `theta` of type `real` (real
values in $\mathbb{R}$). On actual computers, our integers will have
fixed upper and lower bounds and our real numbers are subject to all
the vagaries of numerical floating point calculations.

In addition to its basic type, a type may also have constraints.
Because `N` is a count, it must be greater than or equal to zero,
which we indicate with the bound `lower=0`. Similarly, the variable
`y` is the number of successes out of `N` trials, so it must take on a
value between 0 and `N` (inclusive); that is represented with the
constraint `lower=0, upper=N`. Finally, the variable `theta` is real
and declared to fall in the interval $[0, 1]$ with the constraint
`lower=0, upper=1`. Technically, our bounds are open for real values,
but in practice, we might wind up with 0 or 1 values due to underflow
or rounding errors in floating point arithmetic.

At run time, the compiled Stan program must be given values for `N`
and `theta`, at which point, each iteration it will sample a value of
`y` using its built-in pseudorandom number generator. In code, we
first define a dictionary for our data (variables `N` and `theta`),
then construct an instance of `CmdStanModel` for our model from the
path to its program, and finally sample from the model using the
`sample` method of `CmdStanModel`.

```{python}
N = 100
theta = 0.3
data = {'N': N, 'theta': theta}
model = csp.CmdStanModel(stan_file = '../stan/binomial-rng.stan')
sample = model.sample(data = data, seed = 123,
                      iter_sampling = 10, iter_warmup = 0, chains = 1,
                      show_progress = False, show_console = False)
```

In the `sample` method of the `CmdStanModel` object, we provide the
data, the pseudorandom number generator seed (for reproducibility of
this case study), the number of sampling iterations (10), the number
of warmup iterations (0, because we are just generating which doesn't
need any warmup), the number of Markov chains (1), and we turn off all
the messages. Our initial setup set the logger level to `WARNING` for
the `cmdstanpy` package in order to get rid of the information-level
messages that would otherwise provide updates on a running Stan program.

The `sample` method returns a sample consisting of the specified
number of draws (10 here). We can extract the draws for the variable
`y` as an array and then print them along with our other variables.

```{python}
y = sample.stan_variable('y')
print("N = ", N, ";  theta = ", theta, ";  y(0:10) =", *y.astype(int))
```

Let's put that in a loop and see what it looks like for 10, 100, 1000,
and 10,000 trials.

```{python}
for N in [10, 100, 1_000, 10_000]:
    data = {'N': N, 'theta': theta}
    sample = model.sample(data = data, seed = 123,
                          iter_sampling = 10, iter_warmup = 0, chains = 1,
			  show_progress = False, show_console = False)
    y = sample.stan_variable('y')
    print("N =", N)
    print("  y: ", *y.astype(int))
    print("  est. theta: ", *(y / N))
```

On the first line for $N = 10$ trials, our simple frequency-based
estimates range from 0.2 to 0.5. By the time we have 10,000 trials,
the frequency-based estimates only vary between 0.292 and 0.309. We
know from the _central limit theorem_ that the spread of estimates is
expected to shrink at a rate of $\mathcal{O}(1 / \sqrt{N})$ for $N$
draws (this result is only asymptotic in $N$, but is very close for
large-ish $N$ in practice).

It is hard to scan these results. Let's take 10,000 trials each time
and plot histograms. The following histogram plots the distribution of
estimates based on 10, 100, and 1000 observations over 100,000 simulated trials.

```{python}
np.random.seed(123)
ts = []
ps = []
theta = 0.3
M = 100_000
for N in [10, 100, 1_000]:
    data = {'N': N, 'theta': theta}
    sample = model.sample(data = data, seed = 123,
                          iter_sampling = M, iter_warmup = 0, chains = 1,
			  show_progress = False, show_console = False)
    y = sample.stan_variable('y')
    theta_hat = y / N
    ps.extend(theta_hat)
    ts.extend(itertools.repeat(N, M))
xlabel = 'estimated Pr[success]'    
df = pd.DataFrame({xlabel: ps, 'trials': ts})
mydraw(
    pn.ggplot(df, pn.aes(x = xlabel))
  + pn.geom_histogram(binwidth=0.01)
  + pn.facet_grid('. ~ trials')
  + pn.scales.scale_x_continuous(limits = [0, 1], breaks = [0, 1/4, 1/2, 3/4, 1],
                                 labels = ["0", "1/4", "1/2", "3/4", "1"],
                                 expand=[0, 0])
  + pn.scales.scale_y_continuous(expand=[0, 0, 0.05, 0])
  + pn.theme(aspect_ratio = 1,
             panel_spacing = 0.1,
             strip_text = pn.element_text(size = 6),
             strip_background = pn.element_rect(height=0.08, fill = "lightgray"),
             axis_text_y = pn.element_blank(),
             axis_ticks_major_y = pn.element_blank(),
             axis_ticks_minor_y = pn.element_blank(),
             axis_title_y = pn.element_blank(),
             axis_text_x = pn.element_text(size = 6),
             axis_title_x = pn.element_text(size = 8))
)            
```

The trial size of 10 only has 10 possible values, 0.0, 0.1, ..., 1.0,
so the histogram (technically a bar chart here) just shows the counts
of those outcomes. Here, $y = 3$ is the most prevalent result, with
corresponding estimate for $\theta$ of $y / 10 = 0.3$. The trial size
of 100 looks roughly normal, as it should as a binomial with trials $N
= 100$. By the time we get to $N = 1,000$ trials, the
draws for $y$ concentrate near 300, or near the estimated value of
$0.3$ for $\theta$. As $N$ grows, the central limit theorem tells us
to expect that the width of these histograms to shrink at a rate of
$\mathcal{O}(1 / \sqrt{N})$.


## Monte Carlo and Markov chain Monte Carlo methods

In the previous section, we generated a sample of draws by taking each
value to be an independent coin flip.  The estimates for the true
probabilty of heads based on the sample frequency of positive outcomes
concentrates around the true value as the number of draws increased.

For our applied Bayesian modeling problems, we will not be able to
take independent draws from the densities of interest.  Instead, we
will only be able to construct a _Markov chain_ in which each element
is marginally drawn from the density of interest, but may come with
correlation or anti-correlation.  Markov chains are sequences of
random variables, each of which is conditionally independent given
only the previous element.  That is, a sequence of random variables
$Y_1, Y_2, \ldots$ makes up a Markov chain if
$$
p_{Y_{n+1} | Y_{1}, \ldots Y_N}(y_{n + 1} | y_1, \ldots, y_n)
=
p_{Y_{n+1} \mid Y_n}(y_{n+1}, y_n)
$$

We can illustrate with a simple example of three Markov chains, all of
which have elements that are marginally distributed as
$\textrm{bernoulli}(0.5)$ and thus the long-term average of all chains
should be 0.5.  We will introduce a parameter $\theta \in (0, 1)$ and
take the probabilities to be
\begin{align}
\Pr[Y_{n + 1} &= 1 \mid Y_n = 1] = \theta
\\
\Pr[Y_{n + 1} &= 1 \mid Y_n = 0] = 1 - \theta
\end{align}
The first line says that if the last number we generated is 1, the
probability of the next element being 1 is $\theta$.  The second line
says that if the last number we generated is 0, the probability of the
next element being 0 is $\theta$.

Here is a Stan program that generates the first $M$ entries of
a Markov chain over outputs 0 and 1, with probability $\theta$ of generating
the same output again.

```{.stan filename="stan/markov_autocorelation.stan"}
data {
  int<lower=0> M;
  real<lower=0, upper=1> rho;  // prob of staying in same state
}
generated quantities {
  array[M] int<lower=0, upper=1> y;  // Markov chain
  y[1] = bernoulli_rng(0.5);
  for (m in 2:M) {
    if (y[m - 1] == 1) {
      y[m] = bernoulli_rng(rho);
    } else {
      y[m] = bernoulli_rng(1 - rho);
    }
  } 
}
```

We can fit the model in Python as we did before and extract the simulated
Markov chain $y$.

```{python}
model = csp.CmdStanModel(stan_file = '../stan/markov-autocorrelation.stan')
M = 1000
rhos = []
iterations = []
draws = []
estimates = []
for rho in [0.05, 0.5, 0.95]:
    data = {'M': M, 'rho': rho}
    sample = model.sample(data = data, seed = 123,
                          iter_warmup = 0, iter_sampling = 1, chains = 1,
			  show_progress = False, show_console = False)
    y_sim = sample.stan_variable('y')
    cum_sum = np.cumsum(y_sim)
    its = np.arange(1, M + 1)
    ests = cum_sum / its
    draws.extend(y_sim[0])
    iterations.extend(its)
    estimates.extend(ests)
    rhos.extend(itertools.repeat(str(rho), M))
df = pd.DataFrame({'draw': draws, 'iteration': iterations,
                   'estimate': estimates, 'rho': rhos})
mydraw(
    pn.ggplot(df, pn.aes(x='iteration', y='estimate', group='rho', color='rho'))
    + pn.geom_line()
    + pn.labs(x = "iteration", y = "estimate")
)
```

With a 0.05 probability of staying in the same state, the Markov chain
exhibits strong anti-correlation in its draws, which tend to bounce
back and forth between 0 and 1 almost every iteration.  In contrast,
the 0.95 probability of staying in the same state means the draws have
long sequences of 0s and 1s.  The 0.5 probability produces independent
draws from the Markov chain.  It is clear that the anticorrelated
chain converges much more quickly and more stably than the independent
chain, which in turn converges to the correct estimate of 0.5 much more
quickly than the correlated chain.

## Monte Carlo integration

Bayesian computation relies on computing integrals corresponding to
expectations.  In this section, we will introduce Monte Carlo methods
for calculating integrals with a simple, textbook example of throwing
darts at a board randomly and using the random locations to estimate the
mathematical constant $\pi$.

The idea is that we are going to take a unit square, with values
represented as pairs in $[0, 2]^2$.  Then we are going to generate
points randomly using a uniform distribution over this square.  For
each point, we are going to calculate whether it falls inside the
half-unit circle circumscribed within the square.  The proportion of
such points gives the proportion of the squares volume taken up by the
circle.  Because the square is $2 x 2$, it has an area of 4, so the
circle has an area of 4 times the proportion of points falling in it.

Here's the Stan code.

```{.stan filename="stan/monte-carlo-pi.stan"}
generated quantities {
  real<lower=-1, upper=1> x = uniform_rng(-1, 1);
  real<lower=-1, upper=1> y = uniform_rng(-1, 1);
  int<lower=0, upper=1> inside = sqrt(x^2 + y^2) < 1;
}
```

The program declares variables `x` and `y` and constrains them to fall
in the interval $[-1, 1]$ and assigns them uniform random values.  The
indicator variable `inside` is set to 1 if the Euclidean length of the
vector $\begin{bmatrix}x & y\end{bmatrix}$ is less than 1 (i.e., it
falls within an inscribed unit cirlce) and is set to 0 otherwise.  The
Euclidean distance is derived directly using the Pythagorean theorem.

First, we compile and then sample from the model, taking `M = 10_000` draws.
Then we plot the draws.

```{python}
M = 10_000
model = csp.CmdStanModel(stan_file = '../stan/monte-carlo-pi.stan')
sample = model.sample(chains = 1, iter_warmup = 0, iter_sampling = M,
                      show_progress = False, show_console = False,
		      seed = 123)
x_draws = sample.stan_variable('x')
y_draws = sample.stan_variable('y')
inside_draws = [int(i) for i in sample.stan_variable('inside')]
inside_named_draws = np.array(["out", "in"])[inside_draws]
df = pd.DataFrame({'x': x_draws, 'y': y_draws, 'inside': inside_named_draws})
mydraw(
  pn.ggplot(df, pn.aes(x = 'x', y = 'y', group='inside', color='inside'))
  + pn.geom_point(size = 0.1)
  + pn.labs(x = 'x', y = 'y')
  + pn.coord_fixed(ratio = 1)
)
```

Next, we take the sample mean of the indicators for being inside the
circle, which produces an estimate of the probability of a point being
inside the circle.  Then, we just have to multiply by the square's
area (4) to get our estimate for $\pi$.

```{python}
Pr_is_inside = np.mean(inside_draws)
pi_hat = 4 * Pr_is_inside
print(f"Pr[Y is inside circle] = {Pr_is_inside:.3f};   estimate for pi = {pi_hat:.3f}")
```

The true value of $\pi$ to 3 digits of accuracy is $3.142$, so we are
close, but not exact, as is the nature of Monte Carlo methods.  If we
increase the number of draws, our error will go down.  Theoretically,
with enough draws, we can get any desired precision; in practice, we
don't have that long to wait and have to make due with only a few
digits of accuracy in our Monte Carlo estimates. This is usually not a
problem because statistical uncertainty still dominates our numerical
imprecision in most applications.


# Laplace's problem: Male birth ratio

Bayes formulated a mathematical solution to the _inverse problem_ of
determining a posterior distributon with density $p(\theta \mid y)$
from a prior with density $p(\theta)$, a sampling distribution with
density $p(y \mid \theta)$, and observed data $y$.  But he was not able to
solve the integral presented in the denominator of his theorem and
actually determine the form of the posterior.

## Laplace's data on live births

A decade later, @laplace1774 solved the integral that vexed Bayes and
applied Bayes's ideas to the applied problem of estimating whether a
boy is more likely to be born than a girl. Laplace gathered data on
the sexes of babies in live births in Paris between 1745 and 1770.  

sex | live births
---:|:---
female | 105,287
male | 110,312
: Live births in Paris between 1745 and 1770.


## A Stan program for Laplace's problem

Unlike the first Stan model we saw, which only generates data, the
following Stan program is going to allow us to observe the number of
male births ($y$) and the total number of births ($N$) and estimate
the probability of a male birth ($\theta$) as well as the probability
that boys are more likely to be born than girls ($\theta > 0.5$). The
Stan program to do this is as follows.

```{.stan filename="stan/sex-ratio.stan"}
data {
  int<lower = 0> N;  // number of live births
  int<lower = 0, upper = N> y;  // male births
}
parameters {
  real<lower=0, upper=1> theta;  // chance of boy
}
model {
  theta ~ uniform(0, 1);  // uniform prior
  y ~ binomial(N, theta);  // binomial sampling
}
generated quantities {
  int<lower=0, upper=1> boys_gt_girls = theta > 0.5;
}
```

## Parameter and model blocks

In this Stan program, we see that both the number of total births $N$
and the number of male births $y$ are given as data. Then there are
two additional blocks we did not see in our earlier program, a
_parameters block_, which is used to declare unknown values (here the
male birth rate $\theta$), and a _model block_, which is where we
define our target density, typically factored as a prior and sampling
distribution. The parameters block declares the type of `theta`, which
is a real value constrained to fall in the interval $[0, 1]$. The
model block defines the prior, which we take to be uniform over the
possible values for `theta`. The model block also defines the sampling
distribution, which codes the fact that the observed data `y` was generated
from a binomial distribution with `N` trials and `theta` probability
of a male birth. Finally, we have a generated quantities block that
defines a single binary indicator variable, `boys_gt_girls`. This
variable will take the value 1 if the probability of a boy is greater
than the probability of a girl.

## Sampling from the posterior

When we run a Stan program, what Stan returns is a sequence of $M$
random draws, which are approximately identically distributed
according to the posterior,
$$
\theta^{(1)}, \ldots, \theta^{(M)} \sim p(\theta \mid y)
$$
If we were to take $M \rightarrow \infty$, the draws will converge to
being identically drawn from the posterior. With a large enough finite
$M$, the draws will become numerically indistinguishable from true
draws from the posterior.

Stan uses a _Markov chain Monte Carlo_ (MCMC) algorithm, which can
lead to autocorrelation in the random draws from the posterior.  That
is, the draws are not typically independent, with each draw being
correlated (or anti-correlated) with the previous draw.  This
autocorrelation does not introduce bias into the Monte Carlo
estimates.

Stan uses a dynamically adaptive form of Hamiltonian Monte Carlo (HMC)
known as the no-U-turn sampler (NUTS).  NUTS can be hyperefficient in
the sense of generating anticorrelated draws that can lead to more
efficient Monte Carlo estimates than independent draws in some
cases.

We fit Laplace's model by compling the model, constructing a
dictionary for the data, and then calling the `sample` method on the
compiled model with the dictionary. We call the sample method with
1,000 warmup iterations and 10,000 sampling iterations; we are taking
so many draws in order to draw smooth histograms later.

```{python}
model = csp.CmdStanModel(stan_file = '../stan/sex-ratio.stan')
boys = 110312
girls = 105287
data = {'N': boys + girls, 'y': boys}
M = 10_000
sample = model.sample(data = data, seed = 123,
                      iter_sampling = M, iter_warmup = 1000,
		      show_progress = False, show_console = False)
```

As before, we proceed by first extracting the draws for the variables
`theta` and `boys_gt_girls`.

```{python}
theta_draws = sample.stan_variable('theta')
boys_gt_girls_draws = sample.stan_variable('boys_gt_girls')
```

We can plot a histogram of approximate draws $\theta^{(m)} \sim
p(\theta \mid y)$ from the posterior to give us a sense of the
value of $\theta$ and its uncertainty given our observed data $y$.

```{python}
mydraw(
  pn.ggplot(pd.DataFrame({'theta': theta_draws}), pn.aes(x = 'theta')) +
  pn.geom_histogram(color='white') +
  pn.labs(x = 'θ') +
  pn.theme(axis_text_y = pn.element_blank(),
           axis_title_y = pn.element_blank(),  
           axis_ticks_major_y = pn.element_blank())
)
```

All of the draws have a value for $\theta$ between 0.50 and 0.52.  In
the next sections, we will see how to use these draws to estimate a
single value for $\theta$ as well as to compute probabilities, such as
the probability that $\theta > 0.5$ or $\theta > 0.51$.


## Bayesian point estimates

In Bayesian terms, a _point estimate_ for a parameter $\Theta$
conditioned on some observed data $Y = y$ is a single value
$\hat{\theta} \in \mathbb{R}^D$ that in some way summarizes the
posterior $p(\theta \mid y)$.

### Posterior mean estimator

The most common Bayesian point estimate for a parameter is the
posterior mean,
\begin{align}
\widehat{\theta}
&= \mathbb{E}[\theta \mid y]
\\[6pt]
&= \int_{\Theta} \theta \cdot p(\theta \mid y) \, \textrm{d}\theta
\\[6pt]
&= \lim_{M \rightarrow \infty} \, \frac{1}{M} \sum_{m=1}^M \theta^{(m)}
\\[6pt]
&\approx \frac{1}{M} \sum_{m=1}^M \theta^{(m)},
\end{align}
where in the last two lines, each draw is distributed approximately
according to the posterior, $\theta^{(m)} \sim p(\theta \mid y)$.

For Laplace's model, the estimate for the male birth rate $\theta$
conditioned on the birth data $y$ is calculated as the sample mean
for the extracted draws for `theta`.

```{python}
theta_hat = np.mean(theta_draws)
print(f"estimated theta = {theta_hat:.3f}")
```



### Posterior median estimator, quantiles, and intervals

A popular alternative Bayesian point estimate is the _posterior
median_, $\theta^+$.  The median is such that for each dimension
$d \in 1{:}D$,
$$
\Pr[\Theta_d \leq \theta^+_d] = \frac{1}{2}.
$$

The posterior median can be calculated by taking the posterior
median of the draws,
```{python}
theta_plus = np.median(theta_draws)
print(f"estimated (median) theta = {theta_plus:.3f}")
```
Because our posterior distribution is nearly symmetric with Laplace's
data, the posterior median is very close to posterior median.

#### Quantiles

Other posterior quantiles are estimated the same way.  For example,
if we want the posterior 95% quantile, we just take the empirical
95% point in the sorted chain of draws.  For example, here
are the 5% quantile and 95% quantile for Laplace's posterior,
calculated with empirical quantiles.
```{python}
quantile_05 = np.quantile(theta_draws, 0.025)
quantile_95 = np.quantile(theta_draws, 0.975)
print(f"0.05 quantile = {quantile_05:.3f};  0.95 quantile = {quantile_95:.3f}")
```

#### Posterior intervals

Together, the 5% quantile and 95% quantile give us the bounds of
our 90% _central probability interval_.  That is, it's the interval
containing 90% of the posterior probability mass, with half of the
remaining mass (5%) taking on higher values and the other half of the
remaining mass (5%) taking on lower values.
```{python}
print(f"central 90% posterior interval for theta = ({quantile_05:.3f}, {quantile_95:.3f})")
```
Other intervals are computed in the exact same way.

### Posterior mode estimator

A popular non-Bayesian point estimate is the _posterior mode_
$\theta^*$, defined as the point with the highest posterior density,
$$
\theta^* = \textrm{arg max}_\theta \ p(\theta \mid y).
$$
Although the posterior mode can be calculated in Stan using 
optimization rather than sampling, we do not consider it here.
The posterior mode is sometimes called the _maximum a posteriori_
(MAP) estimator.

### Estimation error and bias

The _error_ of an estimate is its difference from the true value,
$$
\textrm{err} = \hat{\theta} - \theta.
$$
Our estimate $\hat{\theta}$ is implicitly a function of the data $y$
and so is $\textrm{err}$, so we can make this explicit and write
$$
\textrm{err}(y) = \hat{\theta}(y) - \theta.
$$

The _bias_ of an estimator is defined as its expected error,
\begin{align}
\textrm{bias}
&= \mathbb{E}[\textrm{err}(Y)]
\\[6pt]
&= \mathbb{E}[\hat{\theta}(Y) - \theta]
\\[6pt]
&= \int_Y \hat{\theta}(y) - \theta \ \textrm{d}y.
\end{align}

The posterior mean is a popular Bayesian estimator for two reasons.
First, it is an _unbiased_ estimator in the sense of having zero
bias.  Second, it has the minimum expected square error among
unbiased estimators, where the _squared error_ of an estimate is
defined by
$$
\textrm{err}^2(y) = (\hat{\theta}(y) - \theta)^2.
$$

The posterior median has the pleasant property of being robust to
outliers. The posterior mode, or maximum a posteriori estimate, is at
least consistent in the sense of converging to the true value as the
data size grows.

We will concentrate on posterior means in this quick introduction to
Bayes and Stan.


### (Markov chain) Monte Carlo error and effective sample size

The Markov chain we use to sample is itself a random variable.
Re-running the sampler will produce slightly different results due to
Monte Carlo error (the error introduced by usingly only a finite
sample of $M$ draws).  

Stan reports Markov chain Monte Carlo _standard error_ along with
its estimates of the mean.  The MCMC standard error is for a scalar
parameter $\theta_d$ is defined to be
$$
\textrm{mcmc-se}
= \frac{\textrm{sd}[\theta_d \mid y]}{N^{\textrm{eff}}},
$$
where the numerator is the standard deviation of the parameter
$\theta_d$ in the posterior and $N^{\textrm{eff}}$ is the _effective
sample size_.  In the usual central limit theorem, the number of
samples appers here.  The effective sample size for a sample of size
$M$ is defined to be
$$
N^{\textrm{eff}}
= \frac{M}{\textrm{IAT}},
$$
where $\textrm{IAT}$ is the _integrated autocorrelation time_.
The IAT can be thought of as the interval between effectively
independent draws in our Markov chain.  If we have low
autocorrelation, $\textrm{IAT}$ will be close to 1 and if the
autocorrelation is higher, it can be much higher.  If the
$\textrm{IAT}$ is much higher than 100, it can become difficult
to estimate.  If the
autocorrelation is negative, the $\textrm{IAT}$ is less than 1 and the
effective sample size is larger than the number of draws.  Thus
$N^{\textrm{eff}}$ is the number of independent draws that would
lead the same error as our correlation draws using a Markov chain.

## Estimating event probabilities

Laplace wasn't looking for a point estimate for $\theta$.  He wanted to
know the probability that $\theta > \frac{1}{2}$ after observing $y$
male births in $N$ trials.  In the notation of probability theory,
he wanted to estimate an event probability.

A subset of parameters is known as an _event_. We can convert
conditions on parameters into events. For example, the condition
$\theta > \frac{1}{2}$ can be turned into the event
$$
A = \left\{ \theta \in \Theta : \theta > \frac{1}{2} \right\}.
$$
Events are what are assigned probabilities by a _measure_ in probability
theory. Given a probability measure, the probability of the event $A$,
that the rate of boy births is higher than girl births, will be well defined.
Because we can convert conditions to events, we will be
sloppy and treat the conditions as if they were events. This allows us
to write $\Pr[\Theta > \frac{1}{2} \mid N, y]$ for the probabilty of
the event $\Theta > \frac{1}{2}$.

Technically, we will need to use the _indicator function_ $\textrm{I}$,
which maps propositions like $\theta > \frac{1}{2}$ into the value 1
if they are true and 0 if they are false.  

### Event probabilities via indicators

Event probabilities are defined as posterior conditional expectations
of indicator functions for events.
\begin{align}
\Pr[\Theta > 0.5 \mid N, y]
&= \mathbb{E}\!\left[\textrm{I}[\Theta > 0.5] \mid N, y\right]
\\[8pt]
&= \int_{\Theta} \textrm{I}(\theta > 0.5) \cdot p(\theta \mid N, y) \, \textrm{d}\theta
\\[8pt]
&\approx \frac{1}{M} \sum_{m=1}^M \textrm{I}(\theta^{(m)} > 0.5),
\end{align}
where we assume $\theta^{(m)} \sim p(\theta \mid N, y)$ is distributed
according to the posterior for $m \in 1{:}M$. Following physics
conventions, we use square brackets for functors (functions that apply
to functions); that means we write $\textrm{I}[\cdot]$ when we apply
the indicator function to a random variable and 
$\textrm{I}(\cdot)$ when we apply it to a primitive scalar.

### Events as indicators in Stan

In Stan, we code the value of the indicator function directly
and assign it to a variable in the generated quantities block.
```stan
generated quantities {
  int<lower=0, upper=1> boys_gt_girls = theta > 0.5;
}  
```
Conditional expressions like `theta > 0.5` take on the value
1 if they are true and 0 if they are false.  As is conventional in
languages such as C++, the indicator function itself isn't written.

### The answer to Laplace's question

The posterior mean of the variable `boys_gt_girls` is thus our estimate
for $\Pr[\theta > 0.5 \mid N, y]$.  It is essentially 1.  Printing to
15 decimal places, we see

```{python}
Pr_boy_gt_girl = np.mean(boys_gt_girls_draws)
print(f"estimated Pr[boy more likely] = {Pr_boy_gt_girl:.15f}")
```

The value of 1 returned as an estimate brings up the important
problem of numerical precision.  As we can see from the histogram,
all of our sampled values for $\theta$ are greater than $\frac{1}{2}$.

Laplace calculated the result analytically, which is
$$
\Pr\!\left[\theta > \frac{1}{2}\right] \approx 1 - 10^{-27}.
$$
Thus we would need an astronomical number of posterior draws
before we would generate a value of $\theta$ less than $\frac{1}{2}$.
As given, the answer of 1.0 is very close to the true answer and well
within our expected Monte Carlo error.


### MCMC summary statistics from Stan

With Stan, we can print a summary for the variable $\theta$ in the
posterior, which reports all of these values.  We just call The
`.summary()` function on the sample.  

```{python}
sample.summary(sig_figs = 3)
```

The rows are for our random variables, with `lp__` indicating the
unnormalized log density defined by the Stan program (which includes
change of variable adjustments for constrained parameters).  The
other two rows are for variables defined in the Stan program, `theta`,
and `boys_gt_girls`.  The number of significant figures used in the
results can be controlled in the summary function, as can the
quantiles being reported.

The first column reports the posterior mean, and agrees with our
earlier calculations for both variables.  The second column is
the Monte Carlo standard error (based on an estimated effective
sample size) and a posterior standard deviation estimate.  The
next three columns are quantiles we computed earlier, and they also
agree with our calculations.  Next is the effective sample size,
which can vary from variable to variable, and the effective sample
size rate (per second).  The final column reports $\widehat{R}$, which we
discuss in the next section.


# Warmup and convergence monitoring

When running Markov chains, we want to make sure that we have moved far
enough that our draws are approximately from the posterior.  A
standard way to monitor convergence is to start multiple Markov chains
at different initializations (ideally chosen from a diffuse
initialization like a draw from the prior) and measure whether they
are producing draws from the same distirbution.

## Warmup

Stan performs a number of _warmup iterations_ during which time it
tries to find the region in which it should be sampling and then adapt
a good step size and estimate the posterior covariance (just the
diagonal with the variances by defaul).  The step size is used in the
Hamiltonian dynamics simulator and the (co)variance is used as a
preconditioner.

Warmup converges when the step size and posterior covariance estimates
no longer change.  With multiple chains, it's possible to test that
they have all converged to the same step size and covariance estimate.
Typically, we don't bother doing this and just measure our end goal
directly, which is whether we are getting reasonable posterior draws
after warmup.

Warmup doesn't form a single coherent Markov chain because it uses
memory to adapt.  Once Stan starts sampling, the result is a Markov
chain.  All of our posterior analysis will be with draws from the
Markov chain, not from warmup.  We can save and extract the warmup
draws to investigate the behavior of warmup.

## Potential scale reduction and $\widehat{R}$

Stan uses the _potential scale reduction_ statistic $\widehat{R}$
(pronounced ``R hat'').  Given a sequence of Markov chains, Stan
splits them in half to make sure the first halfs and second halfs of
the chain agree, then calculates variances within each chain and
across all chains and compares.  The statistic $\widehat{R}$ converges
to 1 as the Markov chains converge to the same distributions.

## Practical guidelines

A simple rule of thumb is to run four chains as long as necessary with
equal numbers of warmup and sampling iterations until the sample has
$\hat{R} < 1.01$.  Running more warmup iterations is important because
sampling will not be efficient if warmup has not converged and it at
most uses a few more iterations compared to simply extending the
number of sampling iterations.

We also want to make sure that our effective sample size is at least
25 per chain.  It is not that we need so many draws for inference, but
that we do not trust our effective sample size estimator if it is much
lower.   One way to check that the ESS estimator is OK is to double
the number of draws and make sure that the ESS also doubles.  If it
doesn't, it's a sign that the first ESS estimate is unreliable.

## Running chains concurrently

You can set the number of chains to run using the `chains` argument of
the `sampling()` method and you can set the maximum number of chains
to execute concurrently using `parallel_cores` (which defaults to 1,
seqeuntial execution).  If you set the maximum number of parallel
chains to be too low, CPU resources are potentially unused.  If you
set the number too high, then either CPU or memory can bottleneck
performance and cause it to be slower than running with fewer chains
in parallel.  The only advice I can give here is to experiment.  In
personal projects on our own hardware, the goal is usually the largest
effective sample size in the minimum amount of time.  Perhaps we want
to leave enough CPU power left over to continue to work on other
things, or maybe not.  In a server setting, memory usage, latency,
throughput, and I/O need to be balanced more carefully.


# Appendices

# Expectation notation

If we have a (potentially multivariate) random variable $Z$, we write
$\mathbb{E}[Z]$ for its _expectation_, which is defined as its average
value.  This assumes we have a fixed measure to provide a density
$p_Z(z)$ for the random variable $Z$.  We compute the average value by
averaging over the possible values for $Z$ with weights given by its
density,

$$
\mathbb{E}[Z] = \int_{Z} z \cdot p_Z(z) \, \textrm{d}z.
$$

With Bayesian statistics, we are typically interested in conditional
expectations, which is the value of a random variable conditioned on
the observed value of a second random variable.  Suppose $Y$ is a
second random variable and we observe that $Y = y$.  The _conditional
expectation_ of $Z$ given $Y = y$ is written
$$
\mathbb{E}[Z \mid Y = y]
= \int_{Z} z \cdot p(z \mid y) \, \textrm{d}z.
$$
That is, we take a weighted average of the value of $Z$ with weights
determined by the posterior density $p_{Z \mid Y}(z \mid y)$.  As
before, this assumes a fixed, joint measure for $Y$ and $Z$.

We are typically concerned with cases where $Z = f(\Theta)$ is a
function of the parameters $\Theta$ (and perhaps some data, as well),
and the conditioning is with respect to observed data $y$, where we
will drop the explicit $Y = y$ conditioning and just use $y$,
$$
\mathbb{E}[f(\Theta) \mid y]
= \int_{\Theta} f(\theta) \cdot p(\theta \mid y) \, \textrm{d}\theta.
$$
These posterior expectations simply average the value of the function
$f(\theta)$ over the posterior $p(\theta \mid y)$.  All of our
inferences proceed this way---by averaging a quantity of interest
expressed as a function of parameters over the posterior



# Quantiles, medians, and uncertainty intervals

Suppose $Z$ is a univariate random variable (e.g., one of the
parameters, $\Theta_d$).  If $p \in [0, 1]$, the _$p$-quantile_ for a
univariate random variable $Z$, $\textrm{quantile}(Z, p)$, is defined
by
$$
\textrm{quantile}(Z, p) = z
\ \textrm{ if and only if } \
\textrm{Pr}[Z \leq z] = p.
$$
That is, the $p$-quantile of $Z$ is the value $z$ such that the
probability $Z$ is less than or equal to $z$ is $p$.  In Bayesian
applications, we will typically be taking the probability for
functions of parameters $Z = f(\Theta)$ and conditioning on observed data $y$.

The 0.5-quantile is known as the _median_.  There is a 50% chance that
a random variable takes on a value less than its median and a 50%
chance that it takes on a value greater.  Another common Bayesian
estimator for parameters $\Theta$ is their posterior median,
$$
\overline{\theta} = \textrm{quantile}(Z, 0.5).
$$
The median estimator has the property of minimizing expected absolute
<error (in contrast to the posteiror mean estimate, which minimizes
expected squared error), again assuming the model represents the true
data generating process.


If we have two probabilities, $0 \leq p^L \leq p^U \leq 1$, they
define the $(p^L, p^U)$ _posterior interval_ 
$$
\textrm{interval}(Z, p^L, p^U)
= \left(
    \textrm{quantile}(Z, p^L),
    \textrm{quantile}(Z, p^U)
  \right).
$$

The probability that a point falls in the interval is given by the
differences in probabilities,
$$
\textrm{Pr}\!\left[Z \in \textrm{interval}(Z, p^L, p^U)\right] = p^U - p^L.
$$
If $1 - p^U = p^L$, the interval is called the _central $(p^L - p^U)$ interval_.
For example, the central 95% interval for $Z$ is
$\left( \textrm{quantile}(Z, 0.025), \textrm{quantile}(Z, 0.975) \right)$.





# Bayesian statistics

@bayes1763 introduced the paradigm of statistical inference that has
come to be known as Bayesian statistics.  In retrospect, Bayes's idea
is quite simple, involving four conceptually simple steps.

1.  Define a parametric _sampling density_ $p(y \mid \theta)$ which
describes how to generate observations $y$ given parameters $\theta$.
2.  Define a _prior density_ $p(\theta)$ capturing what is known before
observing new data.
3.  Derive the _posterior density_ $p(\theta \mid y) \propto p(y \mid
\theta) \cdot p(\theta)$ via Bayes's rule.
4.  Evaluate _event probabilities_ conditioned on observed data $y$,
such as $\textrm{Pr}[\textrm{cond}(\theta) \mid y]$ for some condition
on the parameters by integrating over the posterior. 

We work through an example end-to-end in the next section.

## Bayes's theorem

Bayes
formalized his approach in the following theorem.

::: {#thm-line}
### Bayes's Theorem

Given a joint density $p(y, \theta)$, the posterior density $p(\theta
\mid y)$ can be defined in terms that only involve the prior
$p(\theta)$ and sampling distribution $p(y \mid \theta)$, as
$$
p(\theta \mid y)
\ = \
\frac{p(y \mid \theta) \cdot p(\theta)}
        {\int_{\Theta} \, p(y \mid \theta) \cdot p(\theta) \,
        \textrm{d}\theta}.
$$

_Proof_:
\begin{align}
p(\theta \mid y)
&=  \frac{p(y, \theta)}
         {p(y)}
& \textrm{[definition of conditional probability]}       
\\[6pt]
&= \frac{p(y \mid \theta) \cdot p(\theta)}
        {p(y)}
& \textrm{[chain rule]} 
\\[6pt]
&= \frac{p(y \mid \theta) \cdot p(\theta)}
        {\int_{\Theta} \, p(y, \theta) \, \textrm{d}\theta}
& \textrm{[law of total probability]}
\\[6pt]
&= \frac{p(y \mid \theta) \cdot p(\theta)}
        {\int_{\Theta} \, p(y \mid \theta) \cdot p(\theta) \,
        \textrm{d}\theta}.
& \textrm{[chain rule]} 
\end{align}
$\blacksquare$
:::

Bayes's theorem allows us to solve the so-called _inverse problem_ of
inferring the posterior $p(\theta \mid y)$ when all we have is the
sampling distribution $p(y \mid \theta)$, the prior $p(\theta)$, and
some observed data $y$.

In most casses, Stan programs only require densities defined up to a
normalizing constant.   This allows us to go a step further and drop
the denominator $p(y)$, which does not depend on $\theta$.
$$
p(\theta \mid y)
\ \propto \
p(y \mid \theta) \cdot p(\theta).
$$

This lets us proceed with only an unnormalized sampling density $p(y
\mid \theta)$ and unnormalized prior $p(\theta)$.  For some
applications to model comparison we will need a normalizing sampling
distribution $p(y \mid \theta)$ in order to make and compare
probabilistic predictions.

# Bayesian inference

Bayesian inference is largely about estimating quantities of interest
based on a probability model and observed data.  In typical applied
Bayesian inference problems, we are interested in three quantities
that can be expressed as expectations: parameter estimates, event
probabilities, and probabilistic prediction.  All of these quantities
are expressed as expectations over the posterior, meaning that they
involve averaging over our uncertainty in parameter values.

We are also interested in uncertainty, which is defined by the
posterior.  We typically summarize uncertainty using quantiles, and in
particular, posterior intervals (sometimes called "credible
intervals").


## Parameter estimation

The first quantity of interest is the value of parameters.  The
standard Bayesian parameter estimate is the posterior mean, or
conditional expectation given the data.  Given a model $p(y, \theta)$
and observed data $y$, the Bayesian posterior mean estimate of the
parameters $\theta$ is

\begin{align}
\widehat{\theta}
&= \mathbb{E}[\Theta \mid y]
\\[6pt]
&= \int_{\Theta} \theta \cdot p(\theta \mid y) \, \textrm{d}\theta.
\end{align}

The posterior mean as a parameter estimate minimizes expected square
error in the estimates if the model is well specified in the sense of
representing the true data-generating process.  Squared error is the squared
$\textrm{L}_2$ norm of the difference between the estimate and the true
parameter values.  We can expand these definitions down to basic form.

\begin{align}
\widehat{\theta}
&= \textrm{arg min}_{u} \ \mathbb{E}\!\left[\left. \left|\left| \, u - \Theta \, \right|\right|^2  \, \right| \, y\right]
\\[6pt]
&= \textrm{arg min}_{u} \ \mathbb{E}\!\left[\left. (u - \Theta)^{\top} \cdot (u - \Theta)  \, \right| \, y\right]
\\[6pt]
&= \textrm{arg min}_{u} \ \mathbb{E}\!\left[\left. \sum_{d=1}^D \, (u_d - \Theta_d)^2  \, \right| \, y\right]
\\[6pt]
&= \textrm{arg min}_{u} \ \sum_{d=1}^D \, \mathbb{E}\!\left[ \left. (u_d - \Theta_d)^2  \, \right| \, y\right]
\\[6pt]
&= \textrm{arg min}_{u} \ \sum_{d=1}^D \, \int_{\Theta} (u_d - \theta_d)^2 \cdot p(\theta \mid y) \, \textrm{d}\theta.
\end{align}

It's clear from the final form that the estimate $\widehat{\theta}$ is determined
by averaging over posterior uncertainty. 


## Event probabilities

An _event_ in statistics is a subset of the parameter space, $A
\subseteq \Theta$, where $\Theta$ is the set of all valid parameter
values.  We usually pick out events using conditions on the parameter
space.  For example, the condition $\theta > 0.5$ defines the
event $A = \left\{ \theta \in \Theta : \theta > 0.5 \right\}$.

The probability of an event conditioned on data is just another
posterior expectation, this time of an indicator variable.

\begin{align}
\textrm{Pr}[A \mid y]
&= \mathbb{E}[\textrm{I}[\Theta \in A] \mid y]
\\[6pt]
&= \int_{\Theta} \textrm{I}(\theta \in A) \cdot p(\theta \mid y) \, \textrm{d}\theta.
\end{align}

The expression $\textrm{I}(\theta \in A)$ takes on value 1 if $\theta
\in A$ and value 0 otherwise.  We write $\textrm{I}[\Theta \in A]$
using square brackets because a random variable is a function, whereas
we write $\textrm{I}(\theta \in A)$ because $\theta \in \mathbb{R}^D$
is a value.


## Posterior predictive inference

Often we are interested in predicting new data $\tilde{y}$ given the
observation of existing data $y$.  This is a form of _posterior
predictive inference_.  For example, $y$ might be the price of a stock
over some time period and $\tilde{y}$ the price of the stock in the
future.  Or $y$ might be the result of past games and $\tilde{y}$ the
winner of tomorrow's game.  Posterior predictive inference is also
cast an expectation, this time of a density.

\begin{align}
p(\tilde{y} \mid y)
&= \mathbb{E}\!\left[ \, p(\tilde{y} \mid \Theta) \mid y \, \right]
\\[6pt]
&= \int_{\Theta} p(\tilde{y} \mid \theta) \cdot p(\theta \mid y) \, \textrm{d}\theta.
\end{align}



# Markov chain Monte Carlo

Stan performs asymptotically exact, full Bayesian inference using
Markov chain Monte Carlo (MCMC).  MCMC starts from an initial value
$\theta^{(0)}$, which can be random, user provided, or a mixture of
both, and then generates a sequence of values
$\theta^{(1)}, \theta^{(2)}, \ldots, \theta^{(m)}, \ldots$ forming a _Markov chain_.  
A sequence forms a Markov chain if each value is generated conditioned on
only hte previous value, so that

$$
\theta^{(m + 1)} \sim q(\theta \mid \theta^{(m)}.
$$

Because of this dependency, the sequence of random variables making up
the Markov chain exhibit a degree of _autocorrelation_, meaning that
draw $\theta^{(m)}$ is correlated with draw $\theta^{(m+1)}$.

We typically assume some mild conditions on the Markov chain
transition.  First, it must be _ergodic_ in the sense of never getting
stuck in such a way it can't visit the rest of the parameter space.
Second, it must be _aperiodic_ in the sense of not cycling regularly
through regions of the parameter space.  Third, it needs to preserve
the target density in the sense that if  $\theta^{(m)} \sim
p(\theta \mid y)$ has the posterior as its marginal distribution, then
$\theta^{(m+1)} \sim p(\theta \mid y)$ also follows the posterior
distribution.  

If the initial value $\theta^{(0)}$ is drawn from the posterior,
$$
\theta^{(0)} \sim p(\theta \mid y),
$$
then each value in the Markov chain will be marginally distributed
according to the posterior,
$$
\theta^{(1)}, \ldots, \theta^{(M)}
\sim p(\theta \mid y).
$$

Typically we cannot draw an initialization from the posterior---if we
could, we'd just use simpler Monte Carlo methods without the Markov
chain dependencies.  In the situation where $\theta^{(0)}$ is not a
draw from the posterior $p(\theta \mid y)$, then as the chain
progresses, it will converge to the right distribution in the sense
that in the limit as $m \rightarrow \infty$, the draws approach the
corect distribution $\theta^{(m)} \sim p(\theta \mid y)$. 

Now suppose we have a psoterior sample of draws $\theta^{(1)}, \ldots,
\theta^{(M)}$. We can estimate expectations by simply plugging in
values of $\theta^{(m)}$ and averaging.  If our chain satisfies the
mild conditions above, we know that we get the right answer asymptotically,

\begin{align}
\mathbb{E}\!\left[f(\theta) \mid y \right]
&= \int_{\Theta} f(\theta) \cdot p(\theta \mid y) \, \textrm{d}\theta
\\[6pt]
&= \lim_{M \rightarrow \infty} \ \frac{1}{M} \sum_{m=1}^M f\!\left( \theta^{(m)} \right).
\end{align}.

With only finite time in practice, we use the initial segment of the
chain to estimate expectations,
$$
\mathbb{E}\!\left[f(\theta) \mid y\right]
\approx \frac{1}{M} \sum_{m=1}^M f(\theta^{(m)}).
$$

If our initial draw is from the posterior, this estimate is unbiased.
In the usual situation, where the initial draw is not from the
posterior, our expectation retains a degree of bias. Nevertheless, the
limit above shows that the bias goes to zero in the limit. In
practice, we typically remove an initial segment of $N$ draws before
the chain has approximately converged to the right distribution, and
average the remaining draws,
$$
\mathbb{E}\!\left[f(\theta) \mid y\right]
\approx \frac{1}{M - N} \sum_{m=N + 1}^M f(\theta^{(m)}).
$$

Given an estimate $\widehat{\theta}$, its _error_ is $\widehat{\theta}
- \theta$. If its expected error is zero, an estimator is said to be
_unbiased_.   If the Monte Carlo draws $\theta^{(1)}, \ldots, \theta^{(M)}$ are
independent, the _central limit theorem_ tells us that our error
follows a normal distribution asymptotically, so that as $M \rightarrow \infty$,
the error of our estimate $\widehat{\theta}$ follows a normal distribution,
$$
\widehat{\theta} - \theta
\sim \textrm{normal}\!\left(0, \frac{\sigma}{\sqrt{M}}\right),
$$
where $\sigma$ is the standard deviation of the variable $\theta$.
Pre-asymptotically, this result holds approximately and will be used
to estimate the distribution of estimation errors.

Because draws in MCMC can be correlated (or even anticorrelated), we
need the MCMC CLT to genralize the central limit theorem to the case
of correlated variables. Here, we can estimate an _effective sample
size_ (ESS), which is the number of independent draws that provide the same
error distribution.  If $M^{\textrm{eff}}$ is the effective sample size of the
Markov chain $\theta^{(1)}, \ldots, \theta^{(M)}$, then the error will
be distributed approximately as

$$
\widehat{\theta} - \theta
\sim \textrm{normal}\!\left(0, \frac{\sigma}{\sqrt{M^{\textrm{eff}}}}\right).
$$

# A/B testing

A common application of statistics is to compare two things, such as
the effectiveness of a new drug versus the current drug used to treat
a condition on the one hand, or the effectiveness of two different ad
presentations in getting users to click through.  This is usually called
_A/B testing_ in a nod to comparing a hypothetical option A and option B.

Let's consider some Mexican restaurants in New York City, Downtown
Bakery II in the East Village, Taqueria Gramercry in Gramercy, and
La Delicias Mexianas in Spanish Harlem.  Here's the number of reviews
and 5-star reviews for these restaurants on the web site Yelp.

| name | 5-star reviews | total reviews |
|:--|--:|--:|
| Downtown Bakery II | 141 | 276 | 0.511 |
| Taqueria Gramercy | 84 | 143 | 0.587 |
| La Delicias Mexicanas | 41 | 87 | 0.471 |

We can estimate a few things.  First, we can estimate the probability
that each restaurant really is a 5-star restaurant.  We will parameterize
this directly with a rate of 5-star reviews parameter for each restaurant.
Then we can rank the restaurants based on their probability of being a 5-star restaurant.

We will assume there are a total of $K$ items being compared.  In
traditional A/B testing, $K = 2$, but our example uses $K = 3$ and our
code works for any $K$.  We will also assume a Dirichlet prior on the
chances of success $\theta$.

```{.stan filename='stan/ab-test.stan'}
data {
  int<lower=0> K;
  array[K] int<lower=0> trials;
  array[K] int<lower=0> successes;
  real<lower=0> alpha;  
  real<lower=0> beta;  
}
parameters {
  array[K] real<lower=0, upper=1> theta;
}
model {
  successes ~ binomial(trials, theta);
  theta ~ beta(alpha, beta);
}
generated quantities {
  array[K] int<lower=0, upper=1> is_best;
  for (k in 1:K) {
    is_best[k] = theta[k] == max(theta);
  }
}
```

We have coded the data for $K$ items directly in terms of number of
trials and number of successes.  We have also supplied the prior for
the probabilities of success as data as `alpha` and `beta`.  The model
is the same binomial as we had before, except now the likelihood and
priors are vectorized.  In general, Stan is able to take something
like the binomial distribution, which has an integer number of trials,
integer number of successes, and a scalar success probability and
take vectors for all of these.  What we have written above is identical
to what we would get with a loop,

```stan
  for (k in 1:K) {
    successes[k] ~ binomial(trials[k], theta[k])
  }
```

The vectorization of `theta` is different in that only `theta` is an
array, whereas `alpha` and `beta` are scalars.  The sampling statement for
`theta` is equivalent to

```stan
  for (k in 1:K) {
    theta[k] ~ beta(alpha, beta);
  }
```

Because `alpha` and `beta` are scalars, they are not indexed.  Rather,
they are _broadcast_, meaning that the same `alpha` and `beta` is
reused for each dimension of `theta`.

So now let's call and fit this model and print the summary.  We
are setting $\alpha = \beta = 2$, which is equivalent to setting
them equal to 1 and adding 2 trials and 1 success to the data for
each restaurant.

```{python}
model = csp.CmdStanModel(stan_file = '../stan/ab-test.stan')
data = {'K': 3, 'trials': [276, 143, 87], 'successes': [141, 84, 41],
        'alpha': 2, 'beta': 2}
sample = model.sample(data = data, seed = 123,
		      show_progress = False, show_console = False)
sample.summary(sig_figs = 2)
```

First, we make sure that our $\widehat{R}$ values are less than 1.01
and that our $N^{\textrm eff}$ are all greater than 25 per chain (4
chains here with default settings).  In fact, we can see that our
sampling is nearly as efficient as if we had independent posterior
draws.  The probability of a 5-star review is our value for `theta`,
which are 51% for Downtown Bakery, 59% for Taqueria Gramercy, and 47%
for La Delicias.  Even so, we see that the probability that Taqueria
Gramercy is the most likely to have their next review be a 5-star
review, it's still only 90% that's the case.  This is because binomial
data is weak and we only have observations in the hundreds.  (Editor:
Don't listen to Yelp---La Delicias is the best of these restaurants by
far.)

# Regression and predicition

In this section, we will go over simple regression models in Stan and
see how to generate predictions for new items based on fitted
parameters.

## Fisher's iris data set

We will analyze Fisher's classic iris data set, which provides sepal
and petal length and width (in centimeters) as well as the species of
iris.  First we read it in, then we will plot petal width versus petal
length, with species indicated by color.

```{python}
df = pd.read_csv('../stan/iris-data.csv')
mydraw(
  pn.ggplot(df, pn.aes(x='petal_width', y='petal_length', color='species')) +
  pn.geom_point() +
  pn.labs(x = "petal width (cm)", y = "petal length (cm)")
)
```

The three species are of very different sizes, but there is a roughly
linear relation between petal width and petal length that fits the
entire
data.

The width values all have exactly one decimal place of accuracy, which
means they were recorded to the nearest millimeter. There are models
that deal with this kind of measurement quantization, but we will not
consider it now and proceed as if there were no rounding of our
measurements.

## Linear regression

A simple regression model where petal width is $x$ and petal length is
$y$ would take
$$
y \sim \textrm{normal}(\alpha + \beta \cdot x, \sigma),
$$
where $\alpha$ is the _intercept_, $\beta$ is the _slope_, and
$\sigma$ is the _error scale_.  Regressions are sometimes expressed
equivalently as
$$
y = \alpha + \beta \cdot x + \epsilon,  \qquad \epsilon \sim \textrm{normal}(0, \sigma)
$$

Here is a simple Stan model to regress petal length on petal width.

```{.stan filename='../stan/iris-petals.stan'}
data {
  int<lower=0> N;
  vector<lower=0>[N] petal_width;
  vector<lower=0>[N] petal_length;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
model {
  petal_length ~ normal(alpha + beta * petal_width, sigma);
  alpha ~ normal(0, 5);
  beta ~ normal(0, 5);
  sigma ~ lognormal(0, 1);
}
```

The data block says there are $N$ observations of petal width and
length. The widths and lengths are declared as vectors, with lower
bounds of zero because lengths cannot be negative. We write the
parameters out in the parameter block, making sure to include the
lower bound for $\sigma$---the program will not work without that.

The model has the regression as written in math. But the math referred
to scalar $x$ and $y$, whereas now we have vectors. The way Stan
works, the normal distribution is applied to each element of the
container, and any non-container is repeated. So this is equivalent to
the less efficient form
```stan
  for (n in 1:N) {
    petal_length[n] ~ normal(alpha + beta * petal_width[n], sigma);
  }  
```
We then have priors for the regression coefficients and error scale.
The coefficients are unconstrained, but the error scale is constrained
to be positive, so we use a lognormal distribution (we could have also
used a half normal and we should if scales near zero are possible).


We can then compile and fit the model and display the resulting
fit for `alpha` and `beta` as a scatterplot.

```{python}
N = df.shape[0]
petal_width = df['petal_width']
petal_length = df['petal_length']
model = csp.CmdStanModel(stan_file = '../stan/iris-petals.stan')
data = {'N': N, 'petal_width': petal_width, 'petal_length': petal_length}
sample = model.sample(data = data, seed = 123,
		      show_progress = False, show_console = False)
sample.summary(sig_figs = 2)
```

This summary doesn't give us a good feeling for the uncertainty in the
linear relationship.  To do that, we will plot multiple draws from the
posterior along with the data.

```{python}
alpha_draws = sample.stan_variable('alpha')
beta_draws = sample.stan_variable('beta')
plot =  pn.ggplot(df, pn.aes(x='petal_width', y='petal_length', color='species'))
plot = plot +  pn.geom_point()
plot = plot +  pn.labs(x = "petal width (cm)", y = "petal length (cm)")
for a, b in zip(alpha_draws[0:20], beta_draws[0:20]):
    plot = plot + pn.geom_abline(intercept = a, slope = b,
                                 alpha = 0.5, size = 0.2)
mydraw(
  plot
)
```

In order to fit all three groups of data, the plot doesn't do such a
great job of fitting any of them---the larger *iris setosa* instances
haver overestimated petal lengths, whereas they are overestimated for
*iris versicolor*.

We didn't include the error scale, but it's roughly 0.5.  That means
it won't be uncommon to get errors greater than 1 or less than -1.
For *iris setosa*, this could easily result in predictions with
negative lengths!

## Log-linear regression

We'll fix both problems in Stan. First, we'll include a regression per
species. Second, we'll convert to the log scale so that our predicted
sizes remain positive.

## Posterior predictive inference

Now let's say we have a new observation where we know the petal width
and want to predict its length.  Mathematically, to make a prediction
for a new item, we use _posteiror predictive inference_.

First, let's consider evaluating the log density of a new petal's
length ($\tilde{y}$) given its observed width ($\tilde{x}$), having
observed our original data $x$ and $y$.  In Bayesian inference,
we evaluate the _posterior predictive distribution_, where we
let $\Theta$ be our random parameters with realization $\theta$,
\begin{align}
p(\tilde{y} \mid \tilde{x}, x, y)
&= \mathbb{E}[p(\tilde{y} \mid \tilde{x}, \theta) \mid x, y]
\\[6pt]
&= \int_{\Theta} p(\tilde{y} \mid \tilde{x}, \theta) \cdot p(\theta \mid x, y) \, \textrm{d}\theta
\\[6pt]
&\approx \frac{1}{M} \sum_{m=1}^M \, p(\tilde{y} \mid \tilde{x}, \theta^{(m)}),
\end{align}
where $\theta^{(1)}, \ldots, \theta^{(m)} \sim p(\theta \mid x, y)$ are draws from the posterior.
This is just marginalizing out the parameters.  It can help to break the
integral down into the two components of uncertainty, sampling uncertainty
due to our sampling distrubiton and posterior uncertainty in the values of our parameters,
$$
\int_{\Theta}
\underbrace{p(\tilde{y} \mid \tilde{x}, \theta)}_{\textrm{sampling uncertainty}} 
\cdot
\underbrace{p(\theta \mid x, y)}_{\textrm{estimation uncertainty}}
\, \textrm{d}\theta
$$
In our case, $\theta = \begin{bmatrix}\alpha & \beta & \sigma\end{bmatrix}$ and the sampling
distribution is
$$
p(\tilde{y} \mid \tilde{x}, \alpha, \beta, \sigma)
=
\textrm{normal}(\tilde{y} \mid \alpha + \beta \cdot \tilde{x}, \sigma).
$$
Even if we know the parameter values $\alpha$, $\beta$, and $\sigma$ exactly, we can
only predict $\tilde{y}$ to within $\epsilon$, where $\epsilon \sim \textrm{normal}(0, \sigma)$.
If we plug in a point estimate $\widehat{\alpha}, \widehat{\beta}, \widehat{\sigma}$ for our parameters,
we might get approximate inference that takes into account sampling uncertainty, but not estimation uncertainty, e.g., 
$$
p(\tilde{y} \mid \tilde{x}, x, y)
\approx
p(\tilde{y} \mid \tilde{x}, \widehat{\alpha}, \widehat{\beta}, \widehat{\sigma}).
$$

So far, this only gives us a way to evaluate the log density of a
resulting outcome $\tilde{y}$ given a predictor $\tilde{x}$.  If we
want to simulate possible $\tilde{y}$, we have to make sure to add
sampling uncertainty and draw
$$
\tilde{y}^{(m)} \sim \textrm{normal}\!\left(\alpha^{(m)} + \beta^{(m)} \cdot \tilde{x} \mid \sigma^{(m)}\right),
$$
where $\alpha^{(m)}, \beta^{(m)}, \sigma^{(m)} \sim p(\alpha, \beta,
\sigma \mid x, y)$ are posterior draws.  In general, if we then want to estimate
$\tilde{y}$, we can take posterior means of these values.  In the case here,
where our sampling distribution is symmetric, we can directly compute
expected values of $\tilde{y}$ as $\alpha + \beta \cdot \tilde{x}$, so we
can get by plugging in those values rather than sampling for an estimate of $\hat{y}$.

Let's put all this together into a Stan program.  First, let's make
posterior predictions for some new $\tilde{y}$.  We can do this with a
Stan program that just includes the parameters and the new data and a
generated quantities block.  We can run the program with the old
sample for our parameters to generate our predictions.  We could've also
just included the generated quantities block in the original program.

```{.stan filename="iris-predict.stan"}
data {
  int<lower=0> N_tilde;
  vector<lower=0>[N_tilde] petal_width_tilde;
}
parameters {
  real alpha;
  real beta;
  real<lower=0> sigma;
}
generated quantities {
  vector<lower=0>[N_tilde] E_petal_length_tilde
    = alpha + beta * petal_width_tilde;
  vector<lower=0>[N_tilde] petal_length_tilde
    = to_vector(normal_rng(E_petal_length_tilde, sigma));
}
```

This program declares two new data variables, `N_tilde` for the
number of predicted items, and `petal_width_tilde`, a vector of
petal widths of size `N_tilde`.  

It is important that this program use _exactly the same parameters_ as
the original program.   After our original fit, we read that sample
back in for the parameters, then run generated quantities (and the
transformed parameter block if there is one).

The generated quantities block first calculates the expected petal
length given the petal width and assigns it to the variable
`E_petal_length_tilde`. This code is vectorized so that it calculates
all of the input petal widths at once.  The second variable is
then set by sampling according to the sampling distribution
using the `normal_rng` function.  This function is also vectorized,
but it returns an array, so we convert it to a vector just to keep
all the types the same.


```{python}
data = {'N_tilde': 3,
        'petal_width_tilde': [0.4, 1.75, 3.8]}
model = csp.CmdStanModel(stan_file = '../stan/iris-posterior-predictive-sim.stan')
pps_sample = model.generate_quantities(data = data, seed = 123,
                                       previous_fit = sample,
                                       show_console = False)
for i in range(3):
  length_draws = pps_sample.stan_variable('petal_length_tilde')[0:100, i]
  E_length_draws = pps_sample.stan_variable('E_petal_length_tilde')[0:100, i]
  print(f"{i=}:  mean(E_petal_length_tilde[{i}]) = {np.mean(E_length_draws):.2f}; sd(E_petal_length_tilde[{i}]) = {np.std(E_length_draws):.2f}")
  print(f"      mean(petal_length_tilde[{i}]) = {np.mean(length_draws):.2f}; sd(petal_length[{i}]) = {np.std(length_draws):.2f}\n")
```

For each of our input petal widths (0.5, 1.75, 3.8), we see the
posterior mean prediction for petal width and its standard deviation
calculated two ways. First, we take the posterior draws for the
expected petal length, `E_petal_length_tilde`, which is just the
linear prediction of petal value. The uncertainty comes only from
estimation uncertainty in $\alpha$ and $\beta$. Second, we take the
posterior draws for petal length, which include an additional normal
error term with scale $\sigma$. The means are roughly the same either
way, but the standard deviation is much higher in the case of
sampling. The second variable, `petal_length_tilde`, includes both
sources of posterior uncertainty, estimation uncertainty and
uncertainty from the sampling distribution.

**Exercise:**  It doesn't really make sense to treat the error here
as normal---it means predictions in the 1cm range and in the 5cm range
have the same error scale.  To make error multiplicative, use a
lognormal rather than normal model.


# References